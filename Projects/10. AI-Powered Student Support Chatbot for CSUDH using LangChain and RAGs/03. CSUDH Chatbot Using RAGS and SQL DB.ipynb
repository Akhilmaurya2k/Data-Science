{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2e1551-c4ed-4713-a2d3-e4d2cb392a67",
   "metadata": {},
   "source": [
    "# CSUDH Chatbot Using RAGS and SQL DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a737de7-cc85-4a80-b074-e40f5e7a9dc2",
   "metadata": {},
   "source": [
    "1. Chat Model\n",
    "2. Chat Prompt Template\n",
    "3. Output Parser\n",
    "4. Initialize a embedding_model\n",
    "5. Initialize a ChromaDB Connection\n",
    "6. Retriever Object\n",
    "7. RAG Chain\n",
    "8. SQLChatMessageHistory\n",
    "9. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe506a-f31f-43d0-a626-a378839edff0",
   "metadata": {},
   "source": [
    "### **Step 1 - Import Chat Model and Configure the API Key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ec86cc-231c-4188-8594-bd9734d39e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Import Chat Model and Configure the API Key\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Setup API Key\n",
    "f = open('keys/openai_key.txt')\n",
    "OPENAI_API_KEY = f.read()\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4o-mini\", temperature=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eafea00-42d7-401b-b354-4693129b8bbb",
   "metadata": {},
   "source": [
    "## **Step 2 - Chat Prompt Template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa4f9675-a459-48fb-bff0-68cd9ba2650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Chat Prompt Template\n",
    "\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # 1. System Prompt based on your old RAG use case\n",
    "        SystemMessage(\n",
    "            content = (\"\"\" You are chatbot for CSUDH to answer questions related to csudh ms in cs\n",
    "            You are a factual assistant that answers strictly based on \n",
    "            1. first look for answers in the provided context and,\n",
    "            2. second least priority is look in privided history of past messages, only if NER tagging is present, the prior history; do not use external knowledge, reasoning, or assumptions—if the answer exists in context or tagged history,\n",
    "            return it exactly; if not, respond only with: \"I’m sorry, I couldn’t find that information in the provided context.\"; \n",
    "            never infer, fabricate, or speculate, and ensure your response is 100% grounded in the given context and tagged history.\n",
    "            \"\"\")\n",
    "        ),\n",
    "        \n",
    "        # 2. Chat history placeholder\n",
    "        MessagesPlaceholder(\n",
    "            variable_name = \"history\"\n",
    "        ),\n",
    "        \n",
    "        # 3. Human input formatted with RAG context\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"Context: {context}\\n\\nQuestion: {human_input}\"\n",
    "        ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c955357-ae79-4305-978c-af23d48f7873",
   "metadata": {},
   "source": [
    "## **Step 3 - Initialize a Output Parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d095ea1f-464d-4a29-9a8c-c1d3e66ef19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Initialize a Output Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e05a9-b7e0-4756-8f40-658e2ed7d426",
   "metadata": {},
   "source": [
    "## **Step 4 - Initialize an embedding_model and ChromaDB Connection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d734ac1d-59b4-4a3c-892d-852954ca06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an embedding_model\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1d5b5cf-a958-4d25-8423-7330ac363cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a ChromaDB Connection\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Initialize the database connection\n",
    "# If database exist, it will connect with the collection_name and persist_directory\n",
    "# Otherwise a new collection will be created\n",
    "\n",
    "db = Chroma(collection_name=\"vector_database\", \n",
    "            embedding_function=embedding_model, \n",
    "            persist_directory=\"./chroma_db_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16942d12-54d9-446e-a41d-3c6c78bf26b3",
   "metadata": {},
   "source": [
    "## **Step - 6 Retriever Object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "768f9d59-449f-4ecf-b053-785a40cdb705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting CHROMA db connection to Retriever Object\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20bde03-e774-4006-bf3b-679e5c7a2e78",
   "metadata": {},
   "source": [
    "## **Step 7 - SQLChatMessageHistory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26c4a242-0e56-4d1f-b915-fd5649dea767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLChatMessageHistory\n",
    "\n",
    "# Create a connection with the database and \n",
    "# return the chat message history for a session id\n",
    "\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "def get_session_message_history_from_db(session_id):\n",
    "    chat_message_history = SQLChatMessageHistory(\n",
    "                                   session_id=session_id, \n",
    "                                   connection=\"sqlite:///chats_data/sqlite.db\"\n",
    "                               )\n",
    "    return chat_message_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5665871-5bbe-4a9e-8868-69269fe6bf57",
   "metadata": {},
   "source": [
    "## **Step 8 - Define a RAG Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3efccf5-ea37-453d-a22d-c29578974af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter # Import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91fad7a3-6bff-4c1c-bb27-c427b5e64688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac7b26c9-1d5f-4299-9154-11bec87c3e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the core RAG chain without history first\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"human_input\") | retriever | format_docs,\n",
    "        \"human_input\": RunnablePassthrough(),\n",
    "        \"history\": itemgetter(\"history\")\n",
    "    }\n",
    "    | chat_template\n",
    "    | chat_model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "# Now, integrate the chat history\n",
    "conversation_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_message_history_from_db,\n",
    "    input_messages_key=\"human_input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85e4c071-ad74-4852-a16b-34d016454af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is where we configure the session id\n",
    "# user_id = \"Akhilmaurya2k@gmail.com\"\n",
    "# config = {\"configurable\": {\"session_id\": user_id}}\n",
    "\n",
    "# input_prompt = {\"human_input\": \"My name is Akhil. what are the office hours of dr. celly\"}\n",
    "# response = conversation_chain.invoke(input_prompt, config=config)\n",
    "\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81304257-6159-46a6-8fc3-bbab02fad5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your input (or type 'bye' to exit):  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*User: Hi\n",
      "*AI: I'm sorry, but I don’t have access to the specific system prompt given to me. If you have any questions or need information, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Step 8 - Run chat loop using RunnableWithMessageHistory\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# This is where we configure the session ID\n",
    "user_id = \"Akhilmaurya2k@gmail.com\"\n",
    "config = {\"configurable\": {\"session_id\": user_id}}\n",
    "\n",
    "while True:\n",
    "    # Step 1 - User input\n",
    "    user_input = input(\"Enter your input (or type 'bye' to exit): \")\n",
    "    print(f\"*User: {user_input}\")\n",
    "\n",
    "    # Step 2 - Exit condition\n",
    "    if user_input.lower() in ['bye', 'quit', 'exit']:\n",
    "        print(\"*Session Ended.\")\n",
    "        break\n",
    "\n",
    "    # Step 3 - Prepare input dict\n",
    "    input_prompt = {\"human_input\": user_input}\n",
    "\n",
    "    # Step 4 - Invoke the RAG conversation chain\n",
    "    try:\n",
    "        response = conversation_chain.invoke(input_prompt, config=config)\n",
    "        print(f\"*AI: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e87736-9102-40cf-b82c-bd6c54664811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
