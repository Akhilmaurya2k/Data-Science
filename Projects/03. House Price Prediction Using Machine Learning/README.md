# ğŸ¡ Multiple Linear Regression on Boston House Price Prediction Dataset  

## ğŸ¯ Objective  
The objective of this project is to build and evaluate Multiple Linear Regression (MLR) models using different approaches to predict house prices based on various features in the Boston Housing dataset. The goal is to explore feature selection techniques, residual analysis, and model evaluation to improve model performance.  

## â“ Problem Statement  
Predicting house prices is a complex task influenced by multiple factors such as location, number of rooms, and economic conditions. This project aims to implement Multiple Linear Regression models using different methodologies to understand the impact of various independent variables on house prices and identify the best modeling approach for accurate predictions.  

## ğŸš€ Approach  
This project follows multiple approaches to building and evaluating MLR models:  

### ğŸ“Œ 1. Multiple Linear Regression using statsmodels  
âœ… Load and explore the data (Exploratory Data Analysis - EDA)  
âœ… Data Preparation (Train-Test Split)  
âœ… Train the model using `statsmodels`  
âœ… Perform manual feature selection based on **p-values** and **Variance Inflation Factor (VIF)**  
   - ğŸ”¹ Forward Feature Selection  
   - ğŸ”¹ Backward Feature Selection  
âœ… Conduct residual analysis on train data  
âœ… Make predictions on test data  
âœ… Evaluate the model using **ğŸ“‰ Root Mean Squared Error (RMSE)** and **ğŸ“Š R-squared (RÂ²)**  

### ğŸ“Œ 2. Multiple Linear Regression using sklearn  
âœ… Load and explore the data (EDA)  
âœ… Data Preparation (Train-Test Split)  
âœ… Train the model using `sklearn`  
âœ… Perform residual analysis on train data  
âœ… Make predictions on test data  
âœ… Evaluate the model using **ğŸ“‰ RMSE** and **ğŸ“Š RÂ²**  

### ğŸ“Œ 3. Feature Selection and Dimensionality Reduction Techniques  
ğŸ”¹ **Recursive Feature Elimination (RFE):** Automatically selects the most important features  
ğŸ”¹ **Principal Component Analysis (PCA):** Reduces dimensionality while preserving variance  
ğŸ”¹ **Lasso Regularization:** Identifies and eliminates less important features using L1 regularization  
ğŸ”¹ **Feature Importance using Ensembles:** Uses ensemble models to determine the most significant predictors  

## ğŸ“Œ Conclusion  
ğŸ“Œ The project demonstrates how different techniques impact model performance and interpretability.  
ğŸ“Œ Manual feature selection using **p-values** and **VIF** improves model efficiency by eliminating multicollinearity.  
ğŸ“Œ **RFE, PCA, and Lasso** provide automated methods for feature selection and dimensionality reduction.  
ğŸ“Œ The final model evaluation using **RMSE and RÂ²** helps in assessing predictive accuracy and generalizability.  
ğŸ“Œ These methodologies can be applied to various real-world regression problems beyond house price prediction.  

## ğŸ› ï¸ Technologies Used  
ğŸ”¹ Python  
ğŸ”¹ pandas, numpy (Data Processing)  
ğŸ”¹ seaborn, matplotlib (Data Visualization)  
ğŸ”¹ scikit-learn (MLR, Feature Selection, Evaluation)  
ğŸ”¹ statsmodels (Statistical Modeling and Inference)  
